# Kurtis E1 Toolkit

**Kurtis** is an experimental fine-tuning, evaluation and inference tool for [Kurtis E1](https://huggingface.co/collections/ethicalabs/kurtis-e1-67a9148e0836885c44c7902c).

![Kurtis E1 in action](images/screenshots/kurtis.png)

Kurtis is a mental-health AI assistant designed with empathy at its core.

Unlike other AI models that aim for peak efficiency, Kurtis prioritizes understanding, emotional nuance, and meaningful conversations.

It won’t solve complex math problems or write code, nor will it generate images or videos.

Instead, Kurtis focuses on being a thoughtful companion, offering support, perspective, and human-like dialogue.

It doesn’t strive to break records or chase artificial intelligence supremacy—its goal is to create a space for genuine interaction.

Whether you need someone to talk to, reflect on ideas with, or engage in insightful discussion, Kurtis is there to listen and respond in an understanding way.

---

Kurtis final model allows users to ask questions related to mental health topics. However, **please note the following disclaimer**:

### Disclaimer

- **Kurtis E1 is not a substitute for professional mental health therapy or advice**.
- The responses generated by this model may be **biased** or **inaccurate**.
- For any serious or urgent mental health concerns, please consult with a **licensed professional**.
- **Kurtis E1** is intended as a supportive tool for **casual conversations**, not for diagnosing or treating any mental health conditions.

## Getting Started

### Prerequisites

- [uv](https://github.com/astral-sh/uv) A tool for Python dependency management.
- **Python 3.12 or higher**.
- Docker (optional, if you plan to use Docker).

### Installation

#### Standard Installation (CPU-only)

```bash
uv sync
```

This installs dependencies without PyTorch (use this for development without GPU acceleration).

#### ROCm GPU Support

For AMD GPUs with ROCm 7.0 support:

```bash
uv sync --group rocm --allow-insecure-host download.pytorch.org
```

This installs PyTorch 2.10.0+ with ROCm 7.0 nightly builds for AMD GPU acceleration.

### Usage

You can interact with Kurtis by either training the model or starting a chat session.

#### Train the Model

### Preprocessing

Before training, preprocess the dataset to apply the chat template formatting:

```bash
uv run kurtis --config-module kurtis.config.default model preprocess --output-path ./processed_dataset
```

This will:
- Load the dataset specified in the config
- Apply the model's chat template to format conversations
- Save the preprocessed dataset to the specified path (default: `./processed_dataset/`)

### Training

To train the model using the provided configuration and dataset:

```bash
uv run kurtis --config-module kurtis.config.default model train --output-dir ./kurtis-v1 --no-push --preprocessed-dataset-path ./processed_dataset
```

**Note:** The training script will automatically use the preprocessed dataset from the specified path if it exists. If not found, it will fall back to loading the dataset from the source (as specified in the config) and apply the chat template on-the-fly during training.

#### Start a Chat Session

To start a conversation with a trained Kurtis model:

```bash
# Using a local trained model
uv run kurtis --config-module kurtis.config.default model chat --model-path ./kurtis-v1/Kurtis-Granite-4.0-350m-Instruct/final_merged_checkpoint

# Or using a model from Hugging Face Hub
uv run kurtis --config-module kurtis.config.default model chat --model-path mrs83/Kurtis-SmolLM2-360M-Instruct
```

#### Evaluate the Model

To evaluate the model:

```bash
uv run kurtis --config-module kurtis.config.default model evaluate --output-dir ./kurtis-v1
```

### Dataset Configuration

You can define your training datasets in a YAML file (e.g., `datasets.yaml`). This allows for flexible composition of datasets from Hugging Face, local files, or other sources.

**Example `datasets.yaml`:**

```yaml
datasets:
  - path: "mrs83/kurtis_mental_health_initial"
    split: "train"
    type: "huggingface"
    prompt_column: "question"
    response_column: "answer"
    domain: "mental-health"
  - path: "tellikoroma/mentalhealth"
    split: "train"
    type: "huggingface"
    prompt_column: "pattern"
    response_column: "response"
    domain: "mental-health"
    select:
      - classes:
          - "tag:greeting"
          - "tag:morning"
        max_samples: 1000
```

**Supported Fields:**

- `path`: Dataset path (Hugging Face hub ID or local path).
- `type`: `huggingface`, `jsonl`, `json`, or `parquet`.
- `split`: Dataset split to load (default: `train`).
- `prompt_column`: Column name for the user prompt.
- `response_column`: Column name for the assistant response.
- `domain`: Domain tag for the dataset.
- `select`: Optional list of filtering rules.
    - `classes`: List of strings to filter by (checks if any column value matches `key:value` or just value).
    - `max_samples`: Maximum number of samples to keep for this rule.

### Command-Line Options

You can view all available command-line options using the `--help` flag, also on sub-commands:

```bash
uv run -m kurtis --help
```

The output will display:

```bash
$ uv run -m kurtis --help
Usage: python -m kurtis [OPTIONS] COMMAND [ARGS]...

  Kurtis Toolkit

Options:
  -c, --config-module TEXT  Kurtis python config module.
  --debug / --no-debug
  -h, --help                Show this message and exit.

Commands:
  dataset
  model


$ uv run -m kurtis dataset --help
...
Debug mode is off
Usage: python -m kurtis dataset [OPTIONS] COMMAND [ARGS]...

Options:
  -h, --help  Show this message and exit.

Commands:
  dpo
  preprocess

$ uv run -m kurtis model --help
...
Debug mode is off
Usage: python -m kurtis model [OPTIONS] COMMAND [ARGS]...

Options:
  -h, --help  Show this message and exit.

Commands:
  chat
  evaluate
  push
  train
  train_dpo

```

### Makefile

A **Makefile** is included to help automate common development and testing tasks.

```
make preprocessing  - Preprocess the data using a pre-trained LLM.
make train          - Train the model.
make chat           - Start a prompt session with the model.
make install        - Install project dependencies using uv.
make eval_model     - Evaluate model.
make docker_build   - Build the Docker image for the project.
make docker_push    - Push the Docker image to the registry.
make docker_run     - Run the Docker container with output mounted.
make docker_train   - Run the training script inside the Docker container.
make docker_chat    - Start a prompt session inside the Docker container.
```

### Docker ROCm (AMD GPU)

For AMD GPU users, a separate Dockerfile is provided to support ROCm 7.1.

**Build the ROCm image:**
```bash
docker build -f Dockerfile.rocm -t kurtis:rocm .
```

**Run training with ROCm:**
```bash
docker run -it --rm \
    --device=/dev/kfd --device=/dev/dri \
    --group-add video \
    -v $(pwd)/output:/app/output \
    kurtis:rocm model train
```

### Evaluation Results

Work in progress.

### License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
